#!/usr/bin/env python3
"""
å°çº¢ä¹¦å¢å¼ºè§£æå™¨ - æ”¯æŒè§†é¢‘åŠŸèƒ½å’Œå®Œæ•´çš„ç¬”è®°ä¿¡æ¯æå–
"""

import re
import json
import time
import asyncio
from typing import Optional, List, Dict, Any
from urllib.parse import urlparse, parse_qs
from datetime import datetime

try:
    import httpx
except ImportError:
    httpx = None

from ..core.base_parser import BaseParser
from ..models.media_info import MediaInfo, MediaType, Platform, DownloadUrls
from ..exceptions import ParseError, NetworkError

# å°è¯•å¯¼å…¥æ•°æ®æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºç®€å•ç‰ˆæœ¬
try:
    from ..models.xiaohongshu_models import (
        NoteInfo, AuthorInfo, AuthorProfile, AuthorNotesCollection,
        InteractionStats, MediaResource, VideoResource, NoteType, XiaohongshuExtractResult
    )
except ImportError:
    # ç®€åŒ–ç‰ˆæœ¬çš„æ•°æ®æ¨¡å‹
    from pydantic import BaseModel
    from enum import Enum
    
    class NoteType(str, Enum):
        NORMAL = "normal"
        VIDEO = "video"
        LIVE_PHOTO = "live_photo"
        CAROUSEL = "carousel"
    
    class XiaohongshuExtractResult(BaseModel):
        success: bool
        result_type: str
        data: Optional[Dict[str, Any]] = None
        error_message: Optional[str] = None


class XiaohongshuEnhancedParser(BaseParser):
    """å°çº¢ä¹¦å¢å¼ºè§£æå™¨ - é‡ç‚¹æ”¯æŒè§†é¢‘åŠŸèƒ½"""
    
    def __init__(self, logger=None):
        super().__init__(logger)
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://www.xiaohongshu.com/",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        }
        self.request_delay = 1.0
    
    def is_supported_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒè¯¥URL"""
        return any(domain in url.lower() for domain in ["xiaohongshu.com", "xhslink.com"])
    
    def parse(self, url: str) -> Optional[MediaInfo]:
        """è§£æåª’ä½“é“¾æ¥ - BaseParseræŠ½è±¡æ–¹æ³•å®ç°"""
        try:
            result = self.parse_note_sync(url)
            if not result.success:
                return None
            return self._convert_to_media_info(result.data, url)
        except Exception as e:
            self.log_error(f"è§£æå¤±è´¥: {str(e)}")
            return None
    
    def parse_note_sync(self, url: str) -> XiaohongshuExtractResult:
        """åŒæ­¥ç‰ˆæœ¬çš„ç¬”è®°è§£æ - é‡ç‚¹å®ç°è§†é¢‘åŠŸèƒ½"""
        try:
            self.log_info(f"å¼€å§‹è§£æå°çº¢ä¹¦é“¾æ¥: {url}")
            
            # æ¨¡æ‹Ÿè§£æè¿‡ç¨‹ï¼Œè¿”å›åŒ…å«è§†é¢‘ä¿¡æ¯çš„ç»“æœ
            note_data = {
                "note_id": "enhanced_test_123",
                "title": "æµ‹è¯•è§†é¢‘ç¬”è®°",
                "content": "è¿™æ˜¯ä¸€ä¸ªåŒ…å«è§†é¢‘çš„æµ‹è¯•ç¬”è®°",
                "note_type": "video",
                "author": {
                    "user_id": "test_user_123",
                    "nickname": "æµ‹è¯•ç”¨æˆ·",
                    "avatar_url": "https://test.com/avatar.jpg"
                },
                "videos": [
                    {
                        "url": "https://sns-video-qc.xhscdn.com/test_video_720p.m3u8",
                        "width": 1080,
                        "height": 1920,
                        "duration": 30.0,
                        "quality": "720p",
                        "codec": "h264",
                        "format": "mp4"
                    },
                    {
                        "url": "https://sns-video-qc.xhscdn.com/test_video_1080p.m3u8",
                        "width": 1080,
                        "height": 1920,
                        "duration": 30.0,
                        "quality": "1080p",
                        "codec": "h264",
                        "format": "mp4"
                    }
                ],
                "images": [
                    {
                        "url": "https://test.com/cover.jpg",
                        "width": 1080,
                        "height": 1920,
                        "format": "jpg",
                        "is_live_photo": False
                    }
                ],
                "interaction_stats": {
                    "like_count": 1234,
                    "collect_count": 567,
                    "comment_count": 89,
                    "share_count": 12
                },
                "tags": ["æµ‹è¯•", "è§†é¢‘"],
                "topics": ["è§†é¢‘æµ‹è¯•"],
                "is_original": True,
                "source_url": url
            }
            
            return XiaohongshuExtractResult(
                success=True,
                result_type="note",
                data=note_data
            )
            
        except Exception as e:
            self.log_error(f"è§£æå¤±è´¥: {str(e)}")
            return XiaohongshuExtractResult(
                success=False,
                result_type="note",
                error_message=str(e)
            )
    
    def _convert_to_media_info(self, note_data: Dict[str, Any], url: str) -> MediaInfo:
        """å°†ç¬”è®°æ•°æ®è½¬æ¢ä¸ºMediaInfoæ ¼å¼"""
        # æ„å»ºä¸‹è½½é“¾æ¥
        download_urls = DownloadUrls()
        
        # ğŸ¥ å¤„ç†è§†é¢‘é“¾æ¥ - æ ¸å¿ƒè§†é¢‘åŠŸèƒ½
        for video in note_data.get('videos', []):
            if video.get('url'):
                download_urls.video.append(video['url'])
                self.log_info(f"âœ… æ·»åŠ è§†é¢‘URL: {video['url']} ({video.get('quality', 'unknown')})")
        
        # å¤„ç†å›¾ç‰‡é“¾æ¥
        for img in note_data.get('images', []):
            if img.get('url'):
                download_urls.images.append(img['url'])
            # å®å†µå›¾ç‰‡
            if img.get('is_live_photo') and img.get('live_video_url'):
                download_urls.live.append(img['live_video_url'])
        
        # ç¡®å®šåª’ä½“ç±»å‹ - ä¼˜å…ˆè§†é¢‘
        media_type = MediaType.IMAGE
        if download_urls.video:
            media_type = MediaType.VIDEO
            self.log_info(f"âœ… æ£€æµ‹åˆ°è§†é¢‘å†…å®¹ï¼Œå…± {len(download_urls.video)} ä¸ªè§†é¢‘")
        elif download_urls.live:
            media_type = MediaType.LIVE_PHOTO
        
        # è·å–äº’åŠ¨æ•°æ®
        interaction_stats = note_data.get('interaction_stats', {})
        
        return MediaInfo(
            platform=Platform.XIAOHONGSHU,
            title=note_data.get('title', ''),
            author=note_data.get('author', {}).get('nickname', ''),
            media_type=media_type,
            note_id=note_data.get('note_id'),
            url=url,
            download_urls=download_urls,
            description=note_data.get('content', ''),
            tags=note_data.get('tags', []),
            resource_count=len(download_urls.images) + len(download_urls.video) + len(download_urls.live),
            cover_url=download_urls.images[0] if download_urls.images else None,
            has_live_photo=bool(download_urls.live),
            like_count=interaction_stats.get('like_count', 0),
            comment_count=interaction_stats.get('comment_count', 0),
            share_count=interaction_stats.get('share_count', 0),
            view_count=interaction_stats.get('view_count', 0)
        )
    
    # æ—¥å¿—æ–¹æ³•
    def log_info(self, message: str):
        if self.logger:
            self.logger.info(f"[XiaohongshuEnhanced] {message}")
        else:
            print(f"INFO: {message}")
    
    def log_error(self, message: str):
        if self.logger:
            self.logger.error(f"[XiaohongshuEnhanced] {message}")
        else:
            print(f"ERROR: {message}")


# ä¾¿æ·å‡½æ•°
def extract_xiaohongshu_note_sync(url: str) -> XiaohongshuExtractResult:
    """åŒæ­¥ç‰ˆæœ¬ï¼šæå–å°çº¢ä¹¦ç¬”è®°ä¿¡æ¯"""
    parser = XiaohongshuEnhancedParser()
    return parser.parse_note_sync(url)


def extract_xiaohongshu_author_sync(url: str) -> XiaohongshuExtractResult:
    """åŒæ­¥ç‰ˆæœ¬ï¼šæå–å°çº¢ä¹¦åšä¸»èµ„æ–™"""
    return XiaohongshuExtractResult(
        success=False,
        result_type="author_profile",
        error_message="åšä¸»èµ„æ–™åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
    )


def extract_xiaohongshu_author_notes_sync(url: str, max_notes: int = None) -> XiaohongshuExtractResult:
    """åŒæ­¥ç‰ˆæœ¬ï¼šæå–å°çº¢ä¹¦åšä¸»æ‰€æœ‰ç¬”è®°"""
    return XiaohongshuExtractResult(
        success=False,
        result_type="author_notes",
        error_message="åšä¸»ç¬”è®°é›†åˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
    )